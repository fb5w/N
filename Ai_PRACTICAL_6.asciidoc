+*In[ ]:*+
[source, ipython3]
----
#Name :- SHIVAM BENDRE
#ROLL NO. :- COTA16
#PRACTICAL 6 :- Implement Employee performance evaluation Expert System.
----


+*In[ ]:*+
[source, ipython3]
----
# Importing the necessary libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')
%matplotlib inline
----


+*In[ ]:*+
[source, ipython3]
----
# Importing the csv file
data = pd.read_csv('Hr.csv')
----


+*In[ ]:*+
[source, ipython3]
----
data.shape
----


+*In[ ]:*+
[source, ipython3]
----
data.columns
----


+*In[ ]:*+
[source, ipython3]
----
data.head(4)
----


+*In[ ]:*+
[source, ipython3]
----
# Looking for missing data
data.info()
----




+*In[ ]:*+
[source, ipython3]
----
# A new pandas Dataframe is created to analyze department wise performance as asked.
dept = data.iloc[:,[5,27]].copy()
dept_per = dept.copy()
----


+*In[ ]:*+
[source, ipython3]
----
# Finding out the mean performance of all the departments and plotting its bar graph using barplot
dept_per.groupby(by='EmpDepartment')['PerformanceRating'].mean()
----


+*In[ ]:*+
[source, ipython3]
----
plt.figure(figsize=(10,4.5)) # Set figure size
sns.barplot(x='EmpDepartment', y='PerformanceRating', data=dept_per)#color='blue') # Create bar plot
plt.title('Performance Rating by Department') # Add title
plt.xlabel('EMP Department') # Add x-axis label
plt.ylabel('Performance Rating') # Add y-axis label
plt.show() # Show the plot
----


+*In[ ]:*+
[source, ipython3]
----
# Analyze each department separately
dept_per.groupby(by='EmpDepartment')['PerformanceRating'].value_counts()
----


+*In[ ]:*+
[source, ipython3]
----
# Creating a new dataframe to analyze each department separately
department = pd.get_dummies(dept_per['EmpDepartment'])
performance = pd.DataFrame(dept_per['PerformanceRating'])
dept_rating = pd.concat([department,performance],axis=1)
----


+*In[ ]:*+
[source, ipython3]
----
# Plotting a separate bar graph for performance of each department using seaborn

plt.figure(figsize=(15, 10)) # Set figure size
plt.suptitle('Performance Rating by Department ->')# Add overall title

plt.subplot(2, 3, 1)
sns.barplot(x='PerformanceRating', y='Sales', data=dept_rating)
plt.title('Sales Department')
plt.xlabel('Performance Rating')
plt.ylabel('Sales')

plt.subplot(2, 3, 2)
sns.barplot(x='PerformanceRating', y='Development', data=dept_rating)
plt.title('Development Department')
plt.xlabel('Performance Rating')
plt.ylabel('Development Department')

plt.subplot(2, 3, 3)
sns.barplot(x='PerformanceRating', y='Research & Development', data=dept_rating)
plt.title('Research & Development Department')
plt.xlabel('Performance Rating')
plt.ylabel('Research & Development Department')

plt.subplot(2, 3, 4)
sns.barplot(x='PerformanceRating', y='Human Resources', data=dept_rating)
plt.title('Human Resources Department')
plt.xlabel('Performance Rating')
plt.ylabel('Human Resources Department')

plt.subplot(2, 3, 5)
sns.barplot(x='PerformanceRating', y='Finance', data=dept_rating)
plt.title('Finance Department')
plt.xlabel('Performance Rating')
plt.ylabel('Finance Department')

plt.subplot(2, 3, 6)
sns.barplot(x='PerformanceRating', y='Data Science', data=dept_rating)
plt.title('Data Science Department')
plt.xlabel('Performance Rating')
plt.ylabel('Data Science Department')

plt.tight_layout() # Improve subplot spacing
plt.show() # Show the plot

----




+*In[ ]:*+
[source, ipython3]
----
# Encoding all the ordinal columns and creating a dummy variable for them to see if there
enc = LabelEncoder()
for i in (2,3,4,5,6,7,16,26):
    data.iloc[:,i] = enc.fit_transform(data.iloc[:,i])
data.head()
----




+*In[ ]:*+
[source, ipython3]
----
data.corr()
----


+*In[ ]:*+
[source, ipython3]
----
# Dropping the first columns as it is of no use for analysis.
data.drop(['EmpNumber'],inplace=True,axis=1)
----


+*In[ ]:*+
[source, ipython3]
----
data.head()
----


+*In[ ]:*+
[source, ipython3]
----
# Here we have selected only the important columns
y = data.PerformanceRating
#X = data.iloc[:,0:-1] All predictors were selected it resulted in dropping of accuracy
X = data.iloc[:,[4,5,9,16,20,21,22,23,24]] # Taking only variables with correlation coef
X.head()
----


+*In[ ]:*+
[source, ipython3]
----
# Splitting into train and test for calculating the accuracy
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=10)
----


+*In[ ]:*+
[source, ipython3]
----
# Standardization technique is used
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
----


+*In[ ]:*+
[source, ipython3]
----
X_train.shape
----


+*In[ ]:*+
[source, ipython3]
----
X_test.shape
----




+*In[ ]:*+
[source, ipython3]
----
# Training the model
from sklearn.ensemble import RandomForestClassifier
classifier_rfg=RandomForestClassifier(random_state=33,n_estimators=23)
parameters=[{'min_samples_split':[2,3,4,5],'criterion':['gini','entropy'],'min_samples_leaf': [1, 2, 3],
             'min_samples_split': [2, 3, 4, 5]}]
model_gridrf=GridSearchCV(estimator=classifier_rfg, param_grid=parameters, scoring='accuracy')
model_gridrf.fit(X_train,y_train)
----


+*In[ ]:*+
[source, ipython3]
----
model_gridrf.best_params_
----


+*In[ ]:*+
[source, ipython3]
----
# Predicting the model
y_predict_rf = model_gridrf.predict(X_test)
----


+*In[ ]:*+
[source, ipython3]
----
# Finding accuracy, precision, recall and confusion matrix
print(accuracy_score(y_test,y_predict_rf))
print(classification_report(y_test,y_predict_rf))
----


+*In[ ]:*+
[source, ipython3]
----
confusion_matrix(y_test,y_predict_rf)
----














+*In[ ]:*+
[source, ipython3]
----

----
